---
title: "Prediction - DA3"
author: "Aftab"
date: "2/5/2022"
output: pdf_document
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
rm(list=ls())


# Descriptive statistics and regressions
library(tidyverse)
library(caret)
library(skimr)
library(grid)
library(glmnet)
library(stargazer)
library(xtable)
#library(directlabels)
library(knitr)
library(cowplot)
library(rattle)
#library(ranger)
#library(Hmisc)
library(kableExtra)
#library(ggcorrplot)
library(modelsummary)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#setwd("C:/Users/Aftab/Courses/DA3/Git-DA3/DA3")
data <- readRDS("A2/working_dataset_greece.RDS")
source("theme_bg.R")
source("da_helper_function.R")
```

```{r, include=FALSE}
# where do we have missing values now?
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]
# No columns with missing observations
```

```{r}
data %>%
  group_by(f_property_type, f_room_type) %>%
  summarise(mean_price = mean(price))

# Creating LOWESS plots to identify the association petween price and the rest of teh variables

# for (i in colnames(data)) {
# 
#   ggplot(data,aes_string(x=i, y="price"))+
#   geom_smooth(method = "loess", formula = y~x, se=FALSE)+ 
#   geom_point()
#   ggsave(paste0("A2/graphs/association/",i,".png"))
# 
# }


data <- data %>% 
  mutate(d_safe = ifelse(d_lockbox == 1 | d_safe == 1, 1, 0)) # Since safe box and lock box are the same

data <- data %>% 
  mutate(d_shared_pool = ifelse(d_shared_pool == 1 | d_shared_outdoor_pool == 1, 1, 0)) # Since shared pool and shared outdoor pool ca be the same

data$n_ln_days_since_last_review <- log(data$n_days_since_last_review)
data$n_ln_number_of_reviews <- data$ln_number_of_reviews
data$n_ln_minimum_nights <- data$n_minimum_nights

# Removing columns based on above created graphs

drop <- c("d_fire_pit", "d_lake_access","d_ping_pong_table", "d_private_hot_tub","d_private_outdoor_heated_pool","d_private_outdoor_pool", "d_private_pool", "f_room_type", "n_number_of_reviews","d_bikes","d_board_games","d_game_console","d_have_fitnessgym","d_have_body_soapgel","d_have_sound_system","d_hot_tub","d_lock_on_bedroom_door","d_lockbox","d_shared_outdoor_pool","n_days_since_last_review","ln_number_of_reviews","n_minimum_nights")

data <- data %>%
  select(-one_of(drop))
```

```{r}
# Checking distributions of variables

for (i in colnames(data)) {

  ggplot(data)+
  geom_density(aes_string(x=i))
  
  ggsave(paste0("A2/graphs/distributions/",i,".png"))

}

ggplot(data, aes(exp(p_host_acceptance_rate/100)))+
  geom_density()
```

```{r}
# Grouping variables

# Basic Variables
basic_lev  <- c("f_property_type","n_accommodates","n_bathrooms","n_bedrooms","n_beds","n_availability_365","d_long_term_stays_allowed","price","d_flag_bedrooms","n_ln_minimum_nights")

reviews <- c("n_review_scores_rating","n_reviews_per_month","flag_review_scores_rating","flag_days_since_last_review","flag_reviews_per_month","n_ln_days_since_last_review","n_ln_number_of_reviews")

host <- c("f_host_response_time","p_host_response_rate","p_host_acceptance_rate","n_days_since_host","d_host_greets_you","d_host_is_superhost","d_host_identity_verified","flag_host_acceptance_rate","flag_host_response_rate","flag_host_response_time")


ammenities <- c("d_bathtub","d_beachfront","d_building_staff","d_carbon_monoxide_alarm","d_cleaning_products","d_cooking_basics","d_dining_table","d_dishes_and_silverware","d_drying_rack_for_clothing","d_elevator","d_essentials","d_extra_pillows_and_blankets","d_fire_extinguisher","d_first_aid_kit","d_hangers","d_hot_water","d_hot_water_kettle","d_laundromat_nearby","d_microwave","d_outdoor_dining_area","d_outdoor_furniture","d_private_entrance","d_roomdarkening_shades","d_safe","d_security_cameras_on_property","d_shared_pool","d_smoke_alarm","d_toaster","d_wine_glasses","d_have_kitchen","d_have_stove","d_have_oven","d_have_frige","d_have_o_machineee_machinecoffee","d_have_wifiinternet","d_have_cable","d_have_tv","d_have_iron","d_have_heating","d_have_air_condfan","d_have_balconyterrace","d_have_garden","d_have_breakfast","d_have_workoffice","d_have_childrenbabycribhighcornerchang","d_have_clothing_storage","d_luggage_dropoff_allowed","d_single_level_home")


```



```{r}
# Checking interactions

price_diff_by_variables4 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){ 
  # Looking for interactions.
  # It is a function it takes 3 arguments: 1) Your dataframe,
  # 2) the factor variable (like room_type)
  # 3)the dummy variable you are interested in (like TV)
  
  # Process your data frame and make a new dataframe which contains the stats
  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)
  
  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(Mean = mean(price, na.rm=TRUE),
                     se = sd(price)/sqrt(n()))
  
  stats[,2] <- lapply(stats[,2], factor)
  
  ggplot(stats, aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2]))+
    geom_bar(stat='identity', position = position_dodge(width=0.9), alpha=0.8)+
    geom_errorbar(aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
                  position=position_dodge(width = 0.9), width = 0.25)+
    scale_color_manual(name=dummy_lab,
                       values=c(color[2],color[1],color[3],color[4])) +
    scale_fill_manual(name=dummy_lab,
                      values=c(color[2],color[1],color[3],color[4])) +
    ylab('Mean Price')+
    xlab(factor_lab) +
    theme_bg()+
    theme(panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),
          panel.border=element_blank(),
          axis.line=element_line(),
          legend.position = "top",
          #legend.position = c(0.7, 0.9),
          legend.box = "vertical",
          legend.text = element_text(size = 5),
          legend.title = element_text(size = 5, face = "bold"),
          legend.key.size = unit(x = 0.4, units = "cm")
    )
}




# Plot interactions between room type/property type and all dummies 
sapply(ammenities, function(x){
  p <- price_diff_by_variables4(data, "f_property_type", x, "property_type", x)
  print(p)
})

# Based on individual box plot for each amenity with property type, following will be interacted with property type

interactions <- c("f_property_type*d_bathtub","f_property_type*d_beachfront","f_property_type*d_extra_pillows_and_blankets","f_property_type*d_hangers","f_property_type*d_hot_water_kettle","f_property_type*d_outdoor_dining_area","f_property_type*d_private_entrance","f_property_type*d_roomdarkening_shades","f_property_type*d_safe","f_property_type*d_security_cameras_on_property","f_property_type*d_shared_pool","f_property_type*d_toaster","f_property_type*d_have_kitchen","f_property_type*d_have_frige","f_property_type*d_have_o_machineee_machinecoffee","f_property_type*d_have_wifiinternet","f_property_type*d_have_cable","f_property_type*d_have_tv","f_property_type*d_have_iron","f_property_type*d_have_heating","f_property_type*d_have_balconyterrace","f_property_type*d_have_childrenbabycribhighcornerchang","f_property_type*d_have_clothing_storage")


```


```{r}
#################################
# Create test and train samples #
#################################
# now all stuff runs on training vs test (holdout), alternative: 4-fold CV


# create test and train samples (80% of observations in train sample)
smp_size <- floor(0.8 * nrow(data))

## K = 5
k_folds <- 5
# Define seed value
seed_val <- 111

train_ids <- sample(seq_len(nrow(data)), size = smp_size)
data$train <- 0
data$train[train_ids] <- 1
# Create train and test sample variables
data_train <- data %>% filter(train == 1)
data_test <- data %>% filter(train == 0)

#####################

```

```{r}
#Bulding the most complex model to use in LASSO
model4 <- paste0(" ~ ",paste(c(basic_lev, reviews, host, ammenities, interactions),collapse = " + "))
```

```{r}
# Creating the most complex OLS model to run a LASSO. Here LASSO is being used as a tool to choose predictors

# Set lasso tuning parameters:
# a) basic setup
train_control <- trainControl( method = "cv", number = k_folds)
# b) tell the actual lambda (penalty parameter) to use for lasso
tune_grid     <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))
# c) create a formula
formula <- formula(paste0("price ", paste(setdiff(model4, "price"), collapse = " + ")))

# Run LASSO
set.seed(seed_val)
lasso_model <- caret::train(formula,
                      data = data_train,
                      method = "glmnet",
                      preProcess = c("center", "scale"),
                      trControl = train_control,
                      tuneGrid = tune_grid,
                      na.action=na.exclude)
# Check the output
lasso_model
# Penalty parameters
lasso_model$bestTune
# Check th optimal lambda parameter
lasso_model$bestTune$lambda
# Check the RMSE curve
plot(lasso_model)

# One can get the coefficients as well
lasso_coeffs <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(coefficient = `s1`)  # the column has a name "1", to be renamed

print(lasso_coeffs)

# Check the number of variables which actually has coefficients other than 0
lasso_coeffs_nz<-lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))

write_csv(lasso_coeffs_nz,"A2/NonZeroCoefficients.csv")

# Get the RMSE of the Lasso model 
#   Note you should compare this to the test RMSE
lasso_fitstats <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) 
lasso_fitstats
# Create an auxilary tibble
lasso_add <- tibble(Model='LASSO', Coefficients=nrow(lasso_coeffs_nz),
                    R_squared=lasso_fitstats$Rsquared, BIC = NA, 
                    Training_RMSE = NA, Test_RMSE = lasso_fitstats$RMSE )

```

```{r}
# modifying the list of variables to be used based on LASSO results

basic_lev <- c("f_property_type","n_accommodates","n_bathrooms","n_bedrooms","n_beds","d_long_term_stays_allowed","n_ln_minimum_nights","d_essentials")

host <- c("f_host_response_time","p_host_acceptance_rate","d_host_greets_you","d_host_identity_verified","flag_host_acceptance_rate")

reviews <- c("flag_review_scores_rating","flag_reviews_per_month","n_ln_number_of_reviews")

ammenities <- c("d_carbon_monoxide_alarm","d_cleaning_products","d_dining_table","d_dishes_and_silverware","d_elevator","d_first_aid_kit","d_outdoor_furniture","d_safe","d_security_cameras_on_property","d_smoke_alarm","d_have_kitchen","d_have_stove","d_have_frige","d_have_o_machineee_machinecoffee","d_have_wifiinternet","d_have_tv","d_have_heating","d_have_breakfast","d_have_childrenbabycribhighcornerchang","d_single_level_home")

interactions <- c("f_property_type*d_bathtub","f_property_type*d_beachfront","f_property_type*d_extra_pillows_and_blankets","f_property_type*d_outdoor_dining_area","f_property_type*d_private_entrance","f_property_type*d_security_cameras_on_property","f_property_type*d_have_o_machineee_machinecoffee","f_property_type*d_have_tv","f_property_type*d_have_balconyterrace","f_property_type*d_have_childrenbabycribhighcornerchang")
```


```{r}
# Building OLS models

model1 <- " ~ n_accommodates"
model2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
model3 <- paste0(" ~ ",paste(c(basic_lev, reviews, host, ammenities),collapse = " + "))
```

```{r}
# Do the iteration

library(fixest)

for ( i in 1:4 ){
  print(paste0( "Estimating model: " ,i ))
  # Get the model name
  model_name <-  paste0("model",i)
  model_pretty_name <- paste0("M",i,"")
  # Specify the formula
  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  
  # Estimate model on the whole sample
  model_work_data <- feols( formula , data = data_train , vcov='hetero' )
  #  and get the summary statistics
  fs  <- fitstat(model_work_data,c('rmse','r2','bic'))
  BIC <- fs$bic
  r2  <- fs$r2
  rmse_train <- fs$rmse
  ncoeff <- length( model_work_data$coefficients )
  
  # Do the k-fold estimation
  set.seed(seed_val)
  cv_i <- train( formula, data_train, method = "lm", 
                 trControl = trainControl(method = "cv", number = k_folds))
  rmse_test <- mean( cv_i$resample$RMSE )
  
  # Save the results
  model_add <- tibble(Model=model_pretty_name, Coefficients=ncoeff,
                      R_squared=r2, BIC = BIC, 
                      Training_RMSE = rmse_train, Test_RMSE = rmse_test )
  if ( i == 1 ){
    model_results <- model_add
  } else{
    model_results <- rbind( model_results , model_add )
  }
}

# Check summary table
# Add it to final results
model_results <- rbind( model_results , lasso_add )
model_results

# As per these results, model4 is clearly overfitted as the R-squared comes out to be 1 with a negative BIC
```

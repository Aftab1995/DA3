---
title: "Prediction Assignment - DA3"
author: "Aftab Alam"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r message=FALSE, warning=FALSE, include=FALSE}
rm(list=ls())


# Descriptive statistics and regressions
library(tidyverse)
library(caret)
library(skimr)
library(grid)
library(glmnet)
library(stargazer)
library(xtable)
#install.packages("directlabels")
library(directlabels)
library(knitr)
library(cowplot)
library(rattle)
#library(Hmisc)
library(kableExtra)
#library(ggcorrplot)
library(modelsummary)
library(ranger)
library(pdp)
library(gbm)
#install.packages('rstan')
#library(rstan)
```

```{r message=FALSE, warning=FALSE, include=FALSE}

# Reading the data
data <- readRDS(gzcon(url("https://github.com/Aftab1995/DA3/blob/main/A2/working_dataset_greece.RDS?raw=true")))

#setwd("C:/Users/Aftab/Courses/DA3/Git-DA3/DA3")

source("A2/theme_bg.R")  
source("A2/da_helper_function.R")



```

```{r eval=FALSE, include=FALSE}
# where do we have missing values now?
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]
# No columns with missing observations
```

```{r message=FALSE, warning=FALSE, include=FALSE}
data %>%
  group_by(f_property_type, f_room_type) %>%
  summarise(mean_price = mean(price))

# Creating LOWESS plots to identify the association petween price and the rest of teh variables

# for (i in colnames(data)) {
# 
#   ggplot(data,aes_string(x=i, y="price"))+
#   geom_smooth(method = "loess", formula = y~x, se=FALSE)+ 
#   geom_point()
#   ggsave(paste0("A2/graphs/association/",i,".png"))
# 
# }


data <- data %>% 
  mutate(d_safe = ifelse(d_lockbox == 1 | d_safe == 1, 1, 0)) # Since safe box and lock box are the same

data <- data %>% 
  mutate(d_shared_pool = ifelse(d_shared_pool == 1 | d_shared_outdoor_pool == 1, 1, 0)) # Since shared pool and shared outdoor pool ca be the same

data$n_ln_days_since_last_review <- log(data$n_days_since_last_review)
data$n_ln_minimum_nights <- data$n_minimum_nights

# Removing columns based on above created graphs

drop <- c("d_fire_pit", "d_lake_access","d_ping_pong_table", "d_private_hot_tub","d_private_outdoor_heated_pool","d_private_outdoor_pool", "d_private_pool", "f_room_type", "n_number_of_reviews","d_bikes","d_board_games","d_game_console","d_have_fitnessgym","d_have_body_soapgel","d_have_sound_system","d_hot_tub","d_lock_on_bedroom_door","d_lockbox","d_shared_outdoor_pool","n_days_since_last_review","n_minimum_nights")

data <- data %>%
  select(-one_of(drop))
```

```{r, include=FALSE, eval=FALSE}
# Checking distributions of variables

for (i in colnames(data)) {

  ggplot(data)+
  geom_density(aes_string(x=i))
  
  ggsave(paste0("A2/graphs/distributions/",i,".png"))

}

ggplot(data, aes(exp(p_host_acceptance_rate/100)))+
  geom_density()
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Grouping variables

# Basic Variables
basic_lev  <- c("f_property_type","f_municipality","n_accommodates","n_bathrooms","n_bedrooms","n_beds","n_availability_365","d_long_term_stays_allowed","price","d_flag_bedrooms","n_ln_minimum_nights")

reviews <- c("n_review_scores_rating","n_reviews_per_month","flag_review_scores_rating","flag_days_since_last_review","flag_reviews_per_month","n_ln_days_since_last_review","n_ln_number_of_reviews")

host <- c("f_host_response_time","p_host_response_rate","p_host_acceptance_rate","n_days_since_host","d_host_greets_you","d_host_is_superhost","d_host_identity_verified","flag_host_acceptance_rate","flag_host_response_rate","flag_host_response_time")


ammenities <- c("d_bathtub","d_beachfront","d_building_staff","d_carbon_monoxide_alarm","d_cleaning_products","d_cooking_basics","d_dining_table","d_dishes_and_silverware","d_drying_rack_for_clothing","d_elevator","d_essentials","d_extra_pillows_and_blankets","d_fire_extinguisher","d_first_aid_kit","d_hangers","d_hot_water","d_hot_water_kettle","d_laundromat_nearby","d_microwave","d_outdoor_dining_area","d_outdoor_furniture","d_private_entrance","d_roomdarkening_shades","d_safe","d_security_cameras_on_property","d_shared_pool","d_smoke_alarm","d_toaster","d_wine_glasses","d_have_kitchen","d_have_stove","d_have_oven","d_have_frige","d_have_o_machineee_machinecoffee","d_have_wifiinternet","d_have_cable","d_have_tv","d_have_iron","d_have_heating","d_have_air_condfan","d_have_balconyterrace","d_have_garden","d_have_breakfast","d_have_workoffice","d_have_childrenbabycribhighcornerchang","d_luggage_dropoff_allowed","d_single_level_home")


```



```{r, eval=FALSE, include=FALSE}
# Checking interactions

price_diff_by_variables4 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){ 
  # Looking for interactions.
  # It is a function it takes 3 arguments: 1) Your dataframe,
  # 2) the factor variable (like room_type)
  # 3)the dummy variable you are interested in (like TV)
  
  # Process your data frame and make a new dataframe which contains the stats
  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)
  
  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(Mean = mean(price, na.rm=TRUE),
                     se = sd(price)/sqrt(n()))
  
  stats[,2] <- lapply(stats[,2], factor)
  
  ggplot(stats, aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2]))+
    geom_bar(stat='identity', position = position_dodge(width=0.9), alpha=0.8)+
    geom_errorbar(aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
                  position=position_dodge(width = 0.9), width = 0.25)+
    scale_color_manual(name=dummy_lab,
                       values=c(color[2],color[1],color[3],color[4])) +
    scale_fill_manual(name=dummy_lab,
                      values=c(color[2],color[1],color[3],color[4])) +
    ylab('Mean Price')+
    xlab(factor_lab) +
    theme_bg()+
    theme(panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),
          panel.border=element_blank(),
          axis.line=element_line(),
          legend.position = "top",
          #legend.position = c(0.7, 0.9),
          legend.box = "vertical",
          legend.text = element_text(size = 5),
          legend.title = element_text(size = 5, face = "bold"),
          legend.key.size = unit(x = 0.4, units = "cm")
    )
}




# Plot interactions between room type/property type and all dummies 
sapply(ammenities, function(x){
  p <- price_diff_by_variables4(data, "f_property_type", x, "property_type", x)
  print(p)
})


```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Based on individual box plot for each amenity with property type, following will be interacted with property type

plot3 <- price_diff_by_variables2(data, "f_property_type", "d_first_aid_kit", "Property Type", "First Aid Kit Available?")

plot4 <- price_diff_by_variables2(data, "f_property_type", "d_dishes_and_silverware", "Property Type", "Dishes & Silverware Available?")

interactions <- c("f_property_type*d_bathtub","f_property_type*f_municipality","f_property_type*d_beachfront","f_property_type*d_extra_pillows_and_blankets","f_property_type*d_hangers","f_property_type*d_hot_water_kettle","f_property_type*d_outdoor_dining_area","f_property_type*d_private_entrance","f_property_type*d_roomdarkening_shades","f_property_type*d_safe","f_property_type*d_security_cameras_on_property","f_property_type*d_shared_pool","f_property_type*d_toaster","f_property_type*d_have_kitchen","f_property_type*d_have_frige","f_property_type*d_have_o_machineee_machinecoffee","f_property_type*d_have_wifiinternet","f_property_type*d_have_cable","f_property_type*d_have_tv","f_property_type*d_have_iron","f_property_type*d_have_heating","f_property_type*d_have_balconyterrace","f_property_type*d_have_childrenbabycribhighcornerchang")


```


```{r message=FALSE, warning=FALSE, include=FALSE}
#################################
# Create test and train samples #
#################################
# now all stuff runs on training vs test (holdout), alternative: 4-fold CV


# create test and train samples (80% of observations in train sample)
# smp_size <- floor(0.8 * nrow(data))
# 
# ## K = 5
k_folds <- 5
# # Define seed value
seed_val <- 111
# 
# train_ids <- sample(seq_len(nrow(data)), size = smp_size)
# data$train <- 0
# data$train[train_ids] <- 1
# # Create train and test sample variables
# data_train <- data %>% filter(train == 1)
# data_test <- data %>% filter(train == 0)

#Saving the split samples and calling them below so that the results may not change. 
# saveRDS(data_train,"A2/data_train.RDS")
# saveRDS(data_test,"A2/data_test.RDS")

# Reading the data
data_test <- readRDS(gzcon(url("https://github.com/Aftab1995/DA3/blob/main/A2/data_test.RDS?raw=true")))
data_train <- readRDS(gzcon(url("https://github.com/Aftab1995/DA3/blob/main/A2/data_train.RDS?raw=true")))
#####################

```

```{r message=FALSE, warning=FALSE, include=FALSE}
#Bulding the most complex model to use in LASSO
model4 <- paste0(" ~ ",paste(c(basic_lev, reviews, host, ammenities, interactions),collapse = " + "))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Creating the most complex OLS model to run a LASSO. Here LASSO is being used as a tool to choose predictors

# Set lasso tuning parameters:
# a) basic setup
train_control <- trainControl( method = "cv", number = k_folds)
# b) tell the actual lambda (penalty parameter) to use for lasso
tune_grid     <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))
# c) create a formula
formula <- formula(paste0("price ", paste(setdiff(model4, "price"), collapse = " + ")))

# Run LASSO
set.seed(seed_val)
lasso_model <- caret::train(formula,
                      data = data_train,
                      method = "glmnet",
                      preProcess = c("center", "scale"),
                      trControl = train_control,
                      tuneGrid = tune_grid,
                      na.action=na.exclude)
# Check the output 

lasso_model
# Penalty parameters
lasso_model$bestTune
# Check th optimal lambda parameter
lasso_model$bestTune$lambda
# Check the RMSE curve
plot(lasso_model)

# One can get the coefficients as well
lasso_coeffs <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(coefficient = `s1`)  # the column has a name "1", to be renamed

print(lasso_coeffs)

# Check the number of variables which actually has coefficients other than 0
lasso_coeffs_nz<-lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))

#write_csv(lasso_coeffs_nz,"A2/NonZeroCoefficients.csv")

# Get the RMSE of the Lasso model 
#   Note you should compare this to the test RMSE
lasso_fitstats <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) 
lasso_fitstats
# Create an auxilary tibble
lasso_add <- tibble(Model='LASSO', Coefficients=nrow(lasso_coeffs_nz),
                    R_squared=lasso_fitstats$Rsquared, BIC = NA, 
                    Training_RMSE = NA, Test_RMSE = lasso_fitstats$RMSE )

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# modifying the list of variables to be used based on LASSO results

basic_lev <- c("f_property_type","n_accommodates","f_municipality","n_bathrooms","n_bedrooms","n_beds","d_long_term_stays_allowed","n_ln_minimum_nights","d_essentials")

host <- c("f_host_response_time","p_host_acceptance_rate","d_host_greets_you","d_host_identity_verified","flag_host_acceptance_rate")

reviews <- c("flag_review_scores_rating","flag_reviews_per_month","n_ln_number_of_reviews")

ammenities <- c("d_carbon_monoxide_alarm","d_cleaning_products","d_dining_table","d_dishes_and_silverware","d_elevator","d_first_aid_kit","d_outdoor_furniture","d_safe","d_security_cameras_on_property","d_smoke_alarm","d_have_kitchen","d_have_stove","d_have_frige","d_have_o_machineee_machinecoffee","d_have_wifiinternet","d_have_tv","d_have_heating","d_have_breakfast","d_have_childrenbabycribhighcornerchang","d_single_level_home")

interactions <- c("f_property_type*d_bathtub","f_property_type*f_municipality","f_property_type*d_beachfront","f_property_type*d_extra_pillows_and_blankets","f_property_type*d_outdoor_dining_area","f_property_type*d_private_entrance","f_property_type*d_security_cameras_on_property","f_property_type*d_have_o_machineee_machinecoffee","f_property_type*d_have_tv","f_property_type*d_have_balconyterrace","f_property_type*d_have_childrenbabycribhighcornerchang")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Building OLS models

model1 <- " ~ n_accommodates"
model2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
model3 <- paste0(" ~ ",paste(c(basic_lev, reviews, host, ammenities,"f_property_type*f_municipality"),collapse = " + ") )
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Do the iteration

library(fixest)

for ( i in 1:4 ){
  print(paste0( "Estimating model: " ,i ))
  # Get the model name
  model_name <-  paste0("model",i)
  model_pretty_name <- paste0("M",i,"")
  # Specify the formula
  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  
  # Estimate model on the whole sample
  model_work_data <- feols( formula , data = data_train , vcov='hetero' )
  #  and get the summary statistics
  fs  <- fitstat(model_work_data,c('rmse','r2','bic'))
  BIC <- fs$bic
  r2  <- fs$r2
  rmse_train <- fs$rmse
  ncoeff <- length( model_work_data$coefficients )
  
  # Do the k-fold estimation
  set.seed(seed_val)
  cv_i <- train( formula, data_train, method = "lm", 
                 trControl = trainControl(method = "cv", number = k_folds))
  rmse_test <- mean( cv_i$resample$RMSE )
  
  # Save the results
  model_add <- tibble(Model=model_pretty_name, Coefficients=ncoeff,
                      R_squared=r2, BIC = BIC, 
                      Training_RMSE = rmse_train, Test_RMSE = rmse_test )
  if ( i == 1 ){
    model_results <- model_add
  } else{
    model_results <- rbind( model_results , model_add )
  }
}

# Check summary table
# Add it to final results
model_results <- rbind( model_results , lasso_add )
model_results

# As per these results, model4 is clearly over fitted as the R-squared comes out to be 1 with a negative BIC. The purpose of model4 was primarily to include all the relevant variables and use it in LASSO to identify predictors with non-zero coefficients. Model 2 turns out to be best in terms of BIC and RMSE is not very different between model 2 and model 4. 

predictors_model2 <- c(basic_lev,"f_property_type*f_municipality")

set.seed(111)
system.time({
ols_model <- train(
  formula(paste0("price ~", paste0(predictors_model2, collapse = " + "))),
  data = data_train,
  method = "lm",
  trControl = train_control
)
})

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Random Forest

predictors <- c(basic_lev, host, reviews, ammenities,interactions)

# set tuning 
tune_grid <- expand.grid(
  .mtry = c(6, 8, 10),
  .splitrule = "variance",
  .min.node.size = c(5, 10, 15)
)

set.seed(111)
system.time({
  rf_model <- train(
    formula(paste0("price ~", paste0(predictors, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity",
  .num.trees=500
  )
})

rf_model

# auto tuning random forest 
set.seed(111)
system.time({
  rf_model_auto <- train(
    formula(paste0("price ~", paste0(predictors, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    importance = "impurity",
  .num.trees=500
  )
})
rf_model_auto

```

```{r message=FALSE, warning=FALSE, include=FALSE}
##Variable Importance Plots rf_model

rf_model_var_imp <- ranger::importance(rf_model$finalModel)/1000
rf_model_var_imp_df <-
  data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_cleansed", "Borough:", varname) ) %>%
  mutate(varname = gsub("f_room_type", "Room type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_var_imp_df

# to have a quick look
plot(varImp(rf_model))

# have a version with top 10 vars only
ggplot(rf_model_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()

##############################
# 2) varimp plot grouped
##############################
# grouped variable importance - keep binaries created off factors together

varnames <- rf_model$finalModel$xNames

f_municipality <- grep("f_municipality",varnames, value = TRUE)
f_host_varnames <- grep("d_host",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)
f_reviews_varnames <- grep("review",varnames, value = TRUE)
amenities_varnames <- c("d_essentials","d_carbon_monoxide_alarm","d_cleaning_products","d_dining_table","d_dishes_and_silverware","d_elevator","d_first_aid_kit","d_outdoor_furniture","d_safe","d_security_cameras_on_property","d_smoke_alarm","d_have_kitchen","d_have_stove","d_have_frige","d_have_o_machineee_machinecoffee","d_have_wifiinternet","d_have_tv","d_have_heating","d_have_breakfast","d_have_childrenbabycribhighcornerchang","d_single_level_home","d_bathtub","d_beachfront","d_extra_pillows_and_blankets","d_outdoor_dining_area","d_private_entrance","d_have_balconyterrace")

groups <- list(Municipality = f_municipality,
               Host_Related=f_host_varnames,
               Property_Type = f_property_type_varnames,
               Reviews = f_reviews_varnames,
               Amenities = amenities_varnames,
               Bathrooms = "n_bathrooms",
               Minimum_Nights = "n_ln_minimum_nights",
               Number_Accommodates = "n_accommodates",
               Beds = "n_beds")

# Need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(ranger::importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}

rf_model_var_imp_grouped <- group.importance(rf_model$finalModel, groups)
rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
                                            imp = rf_model_var_imp_grouped[,1])  %>%
                                      mutate(imp_percentage = imp/sum(imp))

ggplot(rf_model_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()


```

```{r message=FALSE, warning=FALSE, include=FALSE}
##Variable Importance Plots rf_model_auto

rf_model_auto_var_imp <- ranger::importance(rf_model_auto$finalModel)/1000
rf_model_auto_var_imp_df <-
  data.frame(varname = names(rf_model_auto_var_imp),imp = rf_model_auto_var_imp) %>%
  mutate(varname = gsub("f_municipality", "Municipality: ", varname) ) %>%
  mutate(varname = gsub("f_room_type", "Room Type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_auto_var_imp_df

# to have a quick look
plot(varImp(rf_model_auto))

# have a version with top 10 vars only
ggplot(rf_model_auto_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()

##############################
# 2) varimp plot grouped
##############################
# grouped variable importance - keep binaries created off factors together

varnames_auto <- rf_model_auto$finalModel$xNames

f_municipality_auto <- grep("f_municipality",varnames, value = TRUE)
f_host_varnames_auto <- grep("d_host",varnames_auto, value = TRUE)
f_property_type_varnames_auto <- grep("f_property_type",varnames_auto, value = TRUE)
f_reviews_varnames_auto <- grep("review",varnames_auto, value = TRUE)
amenities_varnames_auto <- c("d_essentials","d_carbon_monoxide_alarm","d_cleaning_products","d_dining_table","d_dishes_and_silverware","d_elevator","d_first_aid_kit","d_outdoor_furniture","d_safe","d_security_cameras_on_property","d_smoke_alarm","d_have_kitchen","d_have_stove","d_have_frige","d_have_o_machineee_machinecoffee","d_have_wifiinternet","d_have_tv","d_have_heating","d_have_breakfast","d_have_childrenbabycribhighcornerchang","d_single_level_home","d_bathtub","d_beachfront","d_extra_pillows_and_blankets","d_outdoor_dining_area","d_private_entrance","d_have_balconyterrace")



groups_auto <- list(Municipality = f_municipality_auto,
               Host_Related=f_host_varnames_auto,
               Property_Type = f_property_type_varnames_auto,
               Reviews = f_reviews_varnames_auto,
               Amenities = amenities_varnames_auto,
               Bathrooms = "n_bathrooms",
               Minimum_Nights = "n_ln_minimum_nights",
               Number_Accommodates = "n_accommodates",
               Beds = "n_beds")

# Need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups_auto) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(ranger::importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}

rf_model_auto_var_imp_grouped <- group.importance(rf_model_auto$finalModel, groups)
rf_model_auto_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_auto_var_imp_grouped),
                                            imp = rf_model_auto_var_imp_grouped[,1])  %>%
                                      mutate(imp_percentage = imp/sum(imp))

ggplot(rf_model_auto_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()


```

```{r message=FALSE, warning=FALSE, include=FALSE}
# evaluate random forests 
results <- resamples(
  list(
    model_1  = rf_model,
    model_auto  = rf_model_auto
  )
)
summary(results)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# CART with pruning

# CART with built-in pruning
set.seed(20202020)
system.time({
cart_model <- train(
  formula(paste0("price ~", paste0(predictors, collapse = " + "))),
  data = data_train,
  method = "rpart",
  tuneLength = 10,
  trControl = train_control
)
})
cart_model

library(rpart)
library(rpart.plot)
# Tree graph
rpart.plot(cart_model$finalModel, tweak=1.2, digits=-1, extra=1)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# GBM

gbm_grid <-  expand.grid(interaction.depth = 5, # complexity of the tree
                         n.trees = 250, # number of iterations, i.e. trees
                         shrinkage = 0.1, # learning rate: how quickly the algorithm adapts
                         n.minobsinnode = 20 # the minimum number of training set samples in a node to commence splitting
)


set.seed(111)
system.time({
  gbm_model <- train(formula(paste0("price ~", paste0(predictors, collapse = " + "))),
                     data = data_train,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
gbm_model
gbm_model$finalModel
# save( gbm_model , file = 'gbm_model.RData' )

```


```{r message=FALSE, warning=FALSE, include=FALSE}

# ---- compare these models

final_models <-
  list("OLS" = ols_model,
  "CART" = cart_model,
  "Random forest 1: with tuning provided" = rf_model,
  "Random forest 2: auto tuning" = rf_model_auto,
  "GBM"  = gbm_model)

results <- resamples(final_models) %>% summary()

results


# Model selection is carried out on this CV RMSE
result <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

result



# evaluate preferred model on the holdout set -----------------------------

result_2 <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_test), data_test[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

result_2

```

```{r message=FALSE, warning=FALSE, include=FALSE}

#########################################################################################
# Partial Dependence Plots for the best model; random forest with specified tuning parameters
#########################################################################################

# 1) Property Type
pdp_f_property_type <- pdp::partial(rf_model, pred.var = "f_property_type", 
                          pred.grid = distinct_(data_test, "f_property_type"), 
                          train = data_train)

pdp_f_property_type %>%
  autoplot( ) +
  geom_point(color='red', size=2) +
  geom_line(color='red', size=1) +
  ylab("Predicted price") +
  xlab("Property Type") +
ggthemes::theme_economist()


# 2) Number of accommodates
pdp_n_accommodates <- pdp::partial(rf_model, pred.var = "n_accommodates", 
                               pred.grid = distinct_(data_test, "n_accommodates"), 
                               train = data_train)
pdp_n_accommodates %>%
  autoplot( ) +
  geom_point(color='red', size=4) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_y_continuous(limits=c(60,90), breaks=seq(60,90, by=10)) +
  ggthemes::theme_economist()


# 3) Municipality (neighborhood)
pdp_f_municipality <- pdp::partial(rf_model, pred.var = "f_municipality", 
                               pred.grid = distinct_(data_test, "f_municipality"), 
                               train = data_train)
pdp_f_municipality %>%
  autoplot( ) +
  geom_point(color='red', size=4) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  theme_bw()

####
# Subsample performance: RMSE / mean(y) : Fit in various subsets
# NOTE  we do this on the holdout set.

# 
data_holdout_w_prediction <- data_test %>%
  mutate(predicted_price = predict(rf_model, newdata = data_test))

plot <- pdp_f_municipality %>%
  autoplot( ) +
  geom_point(color='red', size=4) +
  ylab("Predicted price (Euros)") +
  xlab("Municipality") +
  ggthemes::theme_economist()

plot2 <- pdp_n_accommodates %>%
  autoplot( ) +
  geom_point(color='red', size=4) +
  ylab("Predicted price (Euros)") +
  xlab("Accommodates (persons)") +
  scale_y_continuous(limits=c(60,90), breaks=seq(60,90, by=10)) +
  ggthemes::theme_economist()

######### create nice summary table of heterogeneity
a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(n_accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )



b <- data_holdout_w_prediction %>%
  filter(f_municipality %in% c("Heraklion", "Khania",
                                         "Lasithi", "Rethymnon")) %>%
  group_by(f_municipality) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )



c <- data_holdout_w_prediction %>%
  filter(n_beds %in% c("2","3", "4","5","6","7","8")) %>%
  group_by(n_beds) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )


d <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )

e <- data_holdout_w_prediction %>%
  filter(f_property_type %in% c("Entire loft", "Entire serviced apartment")) %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )


# Save output
colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(c) <- c("", "RMSE", "Mean price", "RMSE/price")
d<- cbind("All", d)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(e) <- c("", "RMSE", "Mean price", "RMSE/price")

line1 <- c("Apartment size", "", "", "")
line2 <- c("Beds", "", "", "")
line3 <- c("Municipality", "", "", "")
line4 <- c("Property Type", "", "", "")

result_3 <- rbind(line1,a,line2, c,line3, b,line4, e, d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))

result_3

```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(ggmap)
#####################33

bbox <- c(bottom = 34.8, top = 35.7, right = 26.5, left = 23.5)

cretemap <- get_stamenmap(bbox = bbox, maptype = 'terrain-background', color = c("color", "bw")) 

property_map <- ggmap(cretemap) +
  geom_point(data=data,aes(x=longitude,y=latitude, color = f_municipality)) +
  theme_void() +
  labs(title = "Property Distribution Across The 4 Municipalities of Crete, Greece") + 
  theme(legend.position='bottom', 
        legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 14,family="serif"),
        legend.key = element_rect("white"),  # Key background
        legend.text = element_text(face = "bold", size = 10,family="serif"),   
    # Margins around the full legend area
    legend.box.margin = margin(0, 0, 0, 0, "cm"), 
    # Background of legend area: element_rect()
    legend.box.background = element_rect(color = "black"), 
    # The spacing between the plotting area and the legend box
    legend.box.spacing = unit(0.4, "cm")) +
  labs(x = "Longitude",
       y = "Average Price") +
    scale_colour_manual(values = c("orange", "red", "black","purple"))
#ggsave(paste0("A2/visuals/crete_properties_distribution.png"))

```

## Introduction
The purpose of this project was to help predict prices for our newly built small and mid-sized apartments hosting 2-6 guests in Crete, Greece. The project has utilized multiple prediction models on Airbnb data for Crete, Greece. The data was filtered to property types of apartments/lofts that could accommodate up to 6 individuals.After running different prediction models, the project advises the company to focus on the apartments in the Rethymnon municipality as those might garner higher rental prices, however, the predictive power of the model is weak for this municipality. On the other hand, the model is comparatively better at predicting prices in the remaining 3 municipalities.  The model predicts these prices for municipalities given certain property types, amenities, and a few other requirements based on a Random Forest predictive model that was tuned with specific parameters. These are based on the tuned Random Forest model with the loss function being the root mean squared error (RMSE).

## Data Selection & Engineering
The dataset came with a large number of columns due to the source of it being web-scrapping. Hence, even before thinking about the business specific columns, we dropped the columns such as, host's profile picture url, the scrapping id, listing url etc. In total, we dropped 24 columns in the first stage of the data cleaning.

Then certain variables were formatted and cleaned. Price column had the dollar sign in the observations that we had to remove for two reasons; 1- to make the observations viable for our analysis by  making it numeric, 2- the dollar signed was indicative of it being price and was not currency specific as the currency was euros in the case of our dataset. Then some of the variables were formatted into binary to give 1 or 0 value, for example, "host_is_superhost","host_has_profile_pic".

We had to conduct intensive data cleaning and preparation prior to running the predictive models. A major part of the preparation process was to extract amenities provided at each apartment and pool them into relevant categories. Some of the amenities had to be dropped considering the relevancy with our built properties and the size of the dataset. Amenities such as lake access, private pool, hot tub and a few others which were not relevant in our case; our apartments, for example, currently have a shared pool and there are no lakes near our properties, only the ocean that is covered by another amenity. Moreover, variables were divided into numeric, categorical, and dummy types for easier analysis.

To talk more about how amenities for the properties were provided in the dataset and how these were extracted into individual columns, following is a quick snippet of some of that code. It was one of the challenging tasks of this project. After doing large amount of research, we found some codes from last year's student Github, Viki, who had successfully completed this task. The code first remove the brackets, spaces, and commas from the observations. Then it divides all the individual names in each observations into separate columns in a new data frame. We then defined our list of amenities that we would like to see, based on which a for loop was run that looked at the columns in this new dataframe. If our defined keyword/keywords were found in multiple columns for the same observation, a value of 1 was assigned where the particular keyword was found for the observation across all the newly created columns, otherwise 0. This was done for all our specified keywords to obtain similar results. We then looked at all these newly created columns and only kept the ones which had observations of value 1 at least 1% and at most 99% to bring diversity in the column values. 

```{r, echo=TRUE, eval=FALSE}

# Defining levels and dummies 
levs <- levels(factor(unlist(data$amenities)))
data<-cbind(data,as.data.frame(do.call(rbind, lapply(lapply(data$amenities, factor, levs), table))))

# Looking at the column names we have
levs <- sort(names(ams))

# Merging all the columns with the same column name
ams <- as.data.frame(do.call(cbind, by(t(ams), INDICES= names(ams),FUN=colSums)))

# list of key words to merge together
cat <- c( "kitchen", "stove", "oven", "frige","o_machine|ee_machine|coffee", "gril",
         "free.*on_premises", "free.*street", "paid.*on_premis|valet", "paid.*off_premises|self-parking|parking",
         "wifi|internet", "netflix|tv.*netflix", "cable", "tv", "sound_system",
         "toiletries", "shampoo|conditioner", "body_soap|gel", "hair_dryer", "washer", "dryer", "iron",  
         "heating", "air_cond|fan", "balcony|terrace", "garden",
         "onsite_bar|restaurant", "breakfast",  "work|office", "spa",  "fitness|gym",  
         "children|baby|crib|high|corner|chang", "smoking", "housekeeping", "fireplace", "clothing_storage"
         )

# function to merge columns with the same key word in them
for (i in cat) {
  tdata <- ams %>% select(matches(i))
  ams$new_col <- ifelse(rowSums(tdata)>0, 1, 0)
  names(ams)[names(ams) == "new_col"] <- paste0("have_", i)
  ams <- ams %>% select(-colnames(tdata))} 

# keep only columns where the percentage of 1s is at least 1% and at most 99%
selected <- sapply(names(ams), function(x){
  ratio <- sum(ams[[x]])/nrow(ams)*100
  if (between(ratio, 1, 99)) {
    return(TRUE)
  } else { return(FALSE) }
})

```

The models built for the purpose of this project utilized the Airbnb dataset scraped during the last week of December 2021, for Crete, Greece. The dataset contained information on numerous types of properties, reviews, municipalities, host related variables, and amenities. However, to be in line with the company vision of marketing the small and medium-sized apartments, the project focused on property types of ‘Serviced Apartments, Entire Loft, Home/Apt’ from the dataset. It was further filtered on the number of people the properties could accommodate, which in this case was between 2-6 people. A major downside of this filtering was the extreme reduction in the size of the data set from around 20,000 observations to only around 500 observations. Out of these 500 observations, 80% were used to train the models and the remaining 20% were used as the hold-out, which served as live data to test the models. That said, for the purpose of this project, prediction exercises were conducted on these limited observations to come up with an initial pricing mechanism for feasibility purposes, which can be improved upon later on by doing this exercise on a larger dataset.

Given that the data was scrapped from Airbnb Greece website, some of the neighborhoods were written in Greek which R-Studio could not pick up, making it difficult to make any modifications. However, after careful deliberation, it was decided to divide the observations into 4 major municipalities of Crete, based on the latitude and longitude information of the properties. The map below shows the properties from the dataset mapped as per their municipalities on the island of Crete.

```{r, echo=FALSE, warning=FALSE, message=FALSE }
property_map
```

The dataset also had missing values in various variables, both factor and numeric variables. For factor variables, a flag variable was created that took the value 1 where the original variable was NA and 0 otherwise and the NAs in the original variable were replaced with the word “missing”. For numeric variables, flags were created in the same fashion, however, the NAs were replaced with the median of the original variable. Especially for bathrooms, there was only 1 observation with NA for number of bathrooms and an apartment without a bathroom doesn't make sense. Deep dive into the data suggested that the observation has an apartment that can accommodate 4 people and the average number of bathrooms for apartments with 4 is 1.03, hence imputed this NA with the value 1.

Moreover, there were 89 observations with NA values in number of accommodates. Looking at the median of accommodates for the NAs was 3, which also was the same as median accommodates for n_bedrooms = 1. Hence, we took the number of accommodates and divided it by 2, rounded it up to the nearest integer to get the number of bedrooms. This was also because the median number of accommodates was twice the number of median bedrooms in the dataset. This number was be used to impute the values for NAs in the n_bedrooms. The same logic also applied to the number of beds in an apartment, hence similar methodology was used for imputation there as well. The code snippet below shows the methodology.

```{r, echo=TRUE, eval=FALSE}
data <- data %>%
  mutate(
    n_beds = ifelse(is.na(n_beds), round(n_accommodates / 2), n_beds), #assume that 1 bed corresponds to about 2 accommodates
    n_bedrooms = ifelse(is.na(n_bedrooms), round(n_accommodates / 2), n_bedrooms),) #assume that bedrooms correlate to around half the number of accommodates
```


The reason for creating the flags is that we believe these were missing at random as we did not find a particular pattern in the missing values. Overall, most of our modified columns were given names in a way so that it would be easier for us to drop the remaining columns. For our dummy variables we used the prefix d_, for numeric n_ etc. Following code snippet shows the columns we focused on.


```{r, echo=TRUE, eval=FALSE}
# Creating the working dataset

# keep columns if contain d_, n_, f_, p_, usd_ and some others
data <- data %>%
  select(matches("^d_.*|^n_.*|^f_.*|^p_.*|^usd_.*"), price, id,room_type,property_type, latitude, longitude)

```

Furthermore, we looked at the distributions of all the variables to see if there was a need to convert to log scale. Only 2 variables had to be converted in log scale; the number of reviews and minimum number of nights, because of these having along right tail. Apart from these variables, others had a near normal distribution. We also checked for the association of all the individual variable with our y-variable (price), where all had either a linear or near-linear relationship with it, hence no higher-order polynomials of the variables were considered.
Additionally, we placed a cut off at apartments with a price tag of Euros 300 per night as our small and medium-sized apartments not luxury and are targeted towards the middle and upper-middle class of the economic strata.


```{r message=FALSE, warning=FALSE, include=FALSE}

price_dist <- ggplot(data) +
  aes(x = price) +
  geom_histogram(bins = 60L, fill = "#B22222", color = 'white') +
  labs(
    x = "Price",
    y = "Number Of Observations",
    title = "Distribution Of Price variable"
  ) +
  ggthemes::theme_economist() +
  theme(
    plot.title = element_text(size = 18L,
    face = "bold",
    hjust = 0.5),
    axis.title.y = element_text(size = 13L,
    face = "bold", margin = margin(r=5)),
    axis.title.x = element_text(size = 13L,
    face = "bold")
  )

price_dist

```

Moreover, box plots of property types against price were plotted, conditioned on amenities and municipalities to check for viability of interaction affect on the price. Based on these, we created around 26 interactions between property type and several amenities plus the interaction between property type and their municipalities, to uncover any amenity or municipality specific price effect. 

For example, as shown in the figures below, having a first aid kit in the apartment impacts the prices of the apartments significantly. Similarly, availability of dishes and silverware in the apartments some how negatively impact the prices of the apartments. Without dwelling into the reasoning behind such an impact, we let the data speak for itself and included all similar interactions with the property type in our model to capture them. This is also because of our lack of expertise in this business and hence, we relied heavily on data and core statistical methods. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
plot3 + theme(legend.text=element_text(size=8),legend.title=element_text(size=8),axis.title.y = element_text(size = 11, vjust = 2),
    axis.title.x = element_text(size = 11), axis.text.x = element_text(size=8), axis.text.y = element_text(size=8))
plot4 + theme(legend.text=element_text(size=8),legend.title=element_text(size=8), axis.title.y = element_text(size = 11, vjust = 2),
    axis.title.x = element_text(size = 11), axis.text.x = element_text(size=8), axis.text.y = element_text(size=8))
```

Finally, since the number of observations were extremely small due to specification of our project and the number of available variables were comparatively large, we decided to use the LASSO model as a tool drill down into the variables that LASSO assigned the value of zero to the coefficients. It helped us narrow down the number of predictors to only 54. This was also beneficial because our knowledge of the apartment pricing was limited, and we were not very sure about the relative importance of all the variables. 

Out of these 54 predictors, unique variables were identified and then used in the following prediction exercise.

## Prediction
For the purpose of prediction, we ran a total of 4 different prediction models: a simple Ordinary Least Squared (OLS) model containing basic variables, Classification and Regression Tree (CART) with pruning, two Random Forest (RF) models where 1 was provided with the tuning parameters and the other was run on automatic tuning and lastly a Gradient Boosting Machine (GBM) model.  The results of the cross-validated Root Mean Squared Error (RMSE) on the training sample are provided in the table below. The difference between the two RF models is negligible, however, keeping in mind that the same models would be run again on a larger dataset version of our dataset, we advise to use the RF model with provided tuning parameters due to time efficiency. 

The tables below show the RMSE comparison between the models in the training dataset as well as in the hold-out dataset. We understand that the hold-out dataset is synonymous to live data, but we just wanted to show the performance of all these models in the live data as well. 

```{r, eval=FALSE,message=FALSE, warning=FALSE}
result %>% kbl(caption = "Horse Race of Models - Training data CV RSME", escape = FALSE, digits = 2) %>% 
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling( position = "center")

result_2 %>% kbl(caption = "Horse Race of Models -  Holdout dataset RSME", escape = FALSE, digits = 2) %>% 
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling( position = "center")

```
### OLS
Going into a a little bit of detail about all the models we ran, we first ran the LASSO, however, that was only used as tool for selection of variables, hence it is not a contender for the best model. That said, the training sample RMSE of this LASSO was more or less the same as the simple OLS model that we have used in the horse race. After selection of variables based on the LASSO model, we ran a total of 4 OLS models. The first model was run with number of accommodates as the only predictor, the second model had a few of basic variables that we had clubbed together, in total coefficients. The third model was a bit more complex with 46 coefficients that included basic variables, review related variables, host related variables, and amenities plus an interaction between property type and municipality. The fourth model was the most complex that contained 103 coefficients in total and it returned the highest RMSE and negative BIC, which we suspect could be because of over-fitting as the R-squared was 1. Out of these, we chose model 2 OLS that has an R-squared of 20.4%, very close to LASSO R-squared, BIC of 3858, marginally more than the OLS model 1 with BIC 3827, and RMSE of 33.7 compared to 32.5 of the OLS model 1.

### Random Forest
Next, we ran the Random Forest models with 500 trees in each. The first RF model was tuned with random variables option of 6, 8, 10 and minimum node sizes of 5, 10, and 15. This model returned the best tuning parameters of random variables in each tree as 10 and minimum node size of 5. With these parameters, it returned an RMSE of 30.04. On the other hand, the second Random Forest model was run on auto tuning that resulted in an RMSE of 30.26. The auto-tuned RF model chose the same minimum node size of 5, however, it took the number of random variables in each tree at 38. This auto-tuned RF model was fast to run but only because of the small number of observations in the training dataset, however, it may take a lot longer when run on a larger dataset, hence our preference towards tuned RF model, along with the RMSE values.

We further ran diagnostics on the both RF models using Variable Importance (VI) plots, Partial Dependency (PD) plots, and checking subsample performances. For variable importance plots, we grouped together similar variables and re-calculated their importance to gauge the relative importance of these variable groups in predicting the prices. For the purpose of this report, we are showing the diagnostics of the tuned RF model. Amenities stood at the top with a relative importance of around 34% followed by the type of property with 20% relative importance, as shown in the graph below. Based on this, we recommend the management to focus on the types of amenities provided in the apartment towers. The following VI plot shows the top 9 grouped calculated importance of the variables. Unlike in the case study mentioned in the book that conducted similar analysis on London apartments, amenities and property type are most variables in our model. Whereas, in the case study, number of accommodates and room type were the top 2. Number of accommodates in our model stood at the third place, validating the fact that number of accommodates does play a vital role in pricing of the apartments. Apart from that, similar to the case study, locality of the property, reviews, and number of beds are also a part of these top important variables.

```{r message=FALSE, warning=FALSE, echo=FALSE}
ggplot(rf_model_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()
```

We additionally drilled down into some of these important variables to create PD plots to see how changing the specific predictors value while keeping other predictors constant predicted the prices. Looking at the PD plot for property type suggests focusing more on entire serviced apartments, which may garner higher prices relatively, while keeping other things constant. Similarly, drilling down into municipality suggests focusing more on our properties in the Rythmnon municipality as the model predicts relatively higher prices compared to other municipalities, while keeping other things constant. 

We also looked at the relationship between the predicted prices and number of people a property can accommodate. The relationship seems to be linear, similar to the case study in the book with predicted price being higher for the properties that can accommodate higher number of people. 

```{r message=FALSE, warning=FALSE, echo=FALSE}

plot + theme(
    axis.title.y = element_text(size = 11, vjust = 2),
    axis.title.x = element_text(size = 11)
  )
plot2 + theme(
    axis.title.y = element_text(size = 11, vjust = 2),
    axis.title.x = element_text(size = 11)
  )


```


We also looked at subsample performances for some of the important variables to see how individually these would impact on the price prediction. As shown in the table here, this contradicts with the outcome of the PD plots, where here Lasithi municipality seems to garner higher price predictions with an error of 0.4 Euros per predict Euro in the price. It is possible that this is a result of the small number observations in our training dataset. However, when it comes to entire serviced apartments, this is inline with the PD plot results suggesting focusing more on these property types where the prediction error of 0.5 Euros per predict Euro in the price of 78 Euros. 

Overall, based on these subsample results, when focused on the RMSE per unit of price, the model is relatively better at predicting small apartments (accommodating less than or equal to three individuals), opposite to the case study in the book. The model is relatively better at predicting prices for properties that accommodates 6 people with an error of around 5 cents per predicted price of 1 Euro. It is relatively better at predicting prices for the Rethymnon municipality with an error of 35 cents per predicted price of 1 Euro. Moreover, it is comparatively better at predicting the prices of Entire Serviced Apartments, although the difference compared to Entire Lofts is only marginal.  

```{r, echo=FALSE, message=FALSE, warning=FALSE}
result_3 %>% kbl(caption = "Subsample Analysis", escape = FALSE, digits = 2) %>% 
  kable_classic(full_width = F, html_font = "Cambria", ) %>%
  kable_styling( position = "center" )
```

### CART
For the pruned CART model, the cross validated RMSE was 33.6, which was relatively high compared to the CV RMSE of both RF models. Similar to all other models, CART was also run on basic level variables, host related variables, reviews related variables, amenities, and interaction terms that were filtered using the LASSO model. The resulting tree is as follows, having a minimum of observations of 7 and more in the last nodes. CART seemed to have given high importance to number of people a property can accommodate, followed by the log of reviews and number of bathrooms, host acceptance rate, and some amenities. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
rpart.plot(cart_model$finalModel, tweak=1.2, digits=-1, extra=1)
```

### GBM
The last model we ran was the GBM model. IT was run with an inteaction depth of 5 and the total number of trees run was 250. We set the learning rate at 0.1 and minimum samples at 20. The RMSE for this model was at around 32 Euros, again, more than the two RF models that we had run.

## Conclusion
Based on these model predictions, it is very difficult to drill down into certain predictions. Perhaps it is possible the contradiction between the PD plot results and subsample analysis results could have been because of the very small size of the dataset. If the management is willing to invest in another project where the focus is given on data collection so that the resulting dataset is large enough, the project recommends using the Random Forest model with provided tuning parameters to predict the prices for our apartments in Crete, Greece. Increasing the number of observations may overall increase the predictive power of the models. That said, with the current settings, as mentioned above, the RF tuned model has shown to be more accurate at predicting the prices of 5 and 6 bed properties keeping other things contants, Rethymnon municipality while other things constant, and small apartment sizes while everything else is kept constant.

That said, the following graph plots out the predicted prices versus actual prices on both the training dataset and the holdout dataset based on our best model, tuned RF model. In the plot below, purple points show the predicted vs actual prices for the training dataset and the black squares show the predicted prices vs actual prices in Euros. Looking at the graph, it shows that the prices have been underpredicted overall, again this could be a gift of the very small sample size compared to the number of variables.  

```{r,echo=FALSE, warning=FALSE, message=FALSE}
# FIGURES FOR FITTED VS ACTUAL OUTCOME VARIABLES #
##--------------------------------------------------

Ylev <- data_train[["price"]] 

# Predicted values
prediction_train_pred <- as.data.frame(predict(rf_model, newdata = data_train, interval="predict"))

predictionlev_train <- cbind(data_train[,c("price","n_accommodates")],
                               prediction_train_pred)



# Create data frame with the real and predicted values
dfd <- data.frame(ylev=Ylev, predlev=predictionlev_train[,3] )
# Check the differences
dfd$elev <- dfd$ylev - dfd$predlev
#####
Ylevv <- data_test[["price"]] 

# Predicted values
prediction_test_pred <- as.data.frame(predict(rf_model, newdata = data_test, interval="predict"))

predictionlev_test <- cbind(data_test[,c("price","n_accommodates")],
                               prediction_test_pred)


# Create data frame with the real and predicted values
dfe <- data.frame(ylev=Ylevv, predlev=predictionlev_test[,3] )
# Check the differences
dfe$elev <- dfe$ylev - dfe$predlev

# Plot predicted vs price
level_vs_pred <- ggplot() +
  geom_point(data = dfd,aes(y=Ylev, x=predlev , color = "purple"), color = "purple", size = 1,
             shape = 16, alpha = 1, show.legend=FALSE, na.rm=TRUE) +
  geom_point(data = dfe, aes(y=Ylevv, x=predlev, color = "orange"), color = "black", size = 2,
             shape = 12, alpha = 0.5, show.legend=FALSE, na.rm=TRUE)  +
  geom_segment(aes(x = 0, y = 0, xend = 150, yend =275), size=0.8, color="black", linetype=2) +
  labs(y = "Price (Euros)", x = "Predicted price  (Euros)") +
  ggthemes::theme_economist() +
  labs(title = "Actual Prices vs. Predicted Prices for Training Dataset and Holdout Dataset")+
  scale_fill_manual(values = c("purple","orange"), labels = c("Training Data", "Hold-Out Data")) +
  theme(plot.title = element_text(face = "bold", hjust = -2,size = 11)) 

level_vs_pred


```


However, if the management is to go ahead with the current predictions based on this small sample size, the project advises to weigh the importance of a simple OLS model as well. A very important idea to keep in mind here is that the OLS model could have been chosen as well, due to its simplicity and the smaller number (13) of predictors in comparison to the size of the dataset. The Random Forest model was chosen here because of the small RMSE in the training dataset. Nevertheless, OLS model’s RMSE was roughly 4 Euros higher than the best RF model and if the management is ready to ignore this marginal amount, we advise to utilize the OLS model for prediction on the live data. 

